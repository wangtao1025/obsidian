# AI 课程：词袋模型（BagofWords）

本文对应课程 [rag.docs-hub.com](https://rag.docs-hub.com/) 中的 **BagofWords** 文档，归在 **AI 分类**（检索与排序算法）。词袋模型（Bag of Words，BoW）是一种将文本转换为数值向量的方法：只统计各词出现次数，不考虑词序。可与 [TF-IDF](/ai/AI课程-TF-IDF)、[BM25（rank_bm25）](/ai/AI课程-rank_bm25)、[RAG 与向量基础](/ai/AI课程-RAG与向量基础) 搭配学习。

---

## 1. 什么是词袋模型？

- **核心**：把文本中的词视为装进一个「袋子」里，只统计每个词出现的次数，忽略顺序与位置。
- **词**：文本中的词汇；**袋**：打乱顺序的集合；**模型**：文本 → 数字向量的方法。
- **类比**：购物清单「苹果、香蕉、苹果、橙子」→ 只记苹果(2)、香蕉(1)、橙子(1)。

---

## 2. 为什么需要？

- 计算机只能处理数字；词袋将文本变成**固定长度向量**，便于计算、比较和作为机器学习输入。
- **场景**：文本分类（如垃圾邮件）、情感分析、文档相似度、关键词匹配。

---

## 3. 工作原理（三步骤）

| 步骤 | 说明 |
|------|------|
| **1. 构建词汇表** | 收集所有文档中的不重复词，形成词汇表（如 ["我","喜欢","机器学习","数据"]）。 |
| **2. 词→索引映射** | 为每个词分配索引，便于查找（如 "我"→0, "喜欢"→1）。 |
| **3. 向量化** | 对每个文档生成长度为「词汇表大小」的向量，第 i 位 = 第 i 个词在该文档中的出现次数。 |

示例：句子「我喜欢机器学习」在词汇表 ["数据","我","机器学习","喜欢"] 下 → 向量 `[0,1,1,1]`（「数据」0 次，「我」「机器学习」「喜欢」各 1 次）。

---

## 4. 实现要点

- 用 `set` 收集所有文档中的词并排序得到 `vocabulary`。
- `word_to_index = {word: idx for idx, word in enumerate(vocabulary)}`。
- 向量化函数：初始化 `[0]*len(vocabulary)`，遍历分词结果，若词在 `word_to_index` 中则对应位置 +1，返回向量。
- 新词（不在词汇表中）会被忽略；如需考虑新词，需扩展词汇表或使用 OOV 策略。

---

## 5. 优缺点与适用场景

| 优点 | 缺点 |
|------|------|
| 简单直观、易实现 | **丢失词序**（「狗咬人」与「人咬狗」向量相同） |
| 计算高效、易比较 | **丢失语义**（「喜欢」与「爱」视为不同词） |
| 适用分类、情感、相似度等 | **维度大、稀疏**（词汇表大时向量长且多 0） |
| 可扩展为 TF-IDF、停用词、N-gram | **无法处理词汇表外新词** |

**适用**：文本分类、文档相似度粗算、作为更复杂模型的基线、数据量不大且要求不极高的场景。  
**不适用**：需要语义或词序的任务（如机器翻译、生成、深度语义匹配）。

---

**相关文档**：[RAG 与向量基础](/ai/AI课程-RAG与向量基础) · [知识体系与学习路径](/ai/知识体系与学习路径) · [jieba](/python/AI课程-jieba)（中文分词） · [BagofWords（课程原文）](https://rag.docs-hub.com/html/BagofWords.html)
